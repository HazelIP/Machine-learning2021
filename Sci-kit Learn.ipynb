{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542b1184-170c-4956-92c2-dc223fb9a7f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sci-kit Learn\n",
    "## link:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120287ba-95b9-4238-a8e4-0c142b52fdfe",
   "metadata": {},
   "source": [
    "What is Sci-kit Learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934aed75-029f-4cf1-9796-ecb105daaaa5",
   "metadata": {},
   "source": [
    "## Overview of sci-kit Learn\n",
    "Scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It was initially developed by David Cournapeau in 2007. It features various classification, regression and clustering algorithms and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. (wiki: https://en.wikipedia.org/wiki/Scikit-learn) <br>\n",
    "- built upon SciPy\n",
    "- include NumPy, Matplotlib, Pandas\n",
    "- focus on modeling data, while NumPy, Pandas focus on loading, manipulating and summarizing data [C1] <br/>\n",
    "\n",
    "1. Classification\n",
    "2. Regression\n",
    "3. Clustering\n",
    "4. Dimensionality reduction\n",
    "5. Model selection\n",
    "6. Preprocessing <br/>\n",
    "(from scikit-learn.org)\n",
    "Scikit-learn is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection and evaluation, and many other utilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008396ce-4378-4711-bb2d-7a6f9ba16297",
   "metadata": {},
   "source": [
    "**How does machine learning works?\n",
    "- supervised learning\n",
    "- unsupervise learning\n",
    "- a data set is divided into training set and testing set, then evaluate its predictability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e21b11c-6120-415b-b018-3b94e0d792e2",
   "metadata": {},
   "source": [
    "I. Supervised learning: learn from sameple data to predict with new data\n",
    "*  Classification: discrete form, a limited number of categories. aim to label them with correct category or class\n",
    "*  Regression: continuous variables, e.g. prediction of salmon's length as a function of its age and weight\n",
    "\n",
    "II. Unsupervised learning: consists sets of input without corresponding target values \n",
    "*   Clustering: aim to discover groups of similar examples within the data\n",
    "*   Density estimation: aim to determine the distribution of data within the sample OR project data from high-dimensional space down to 2/3D for the purpose of visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedee6f-d932-4fbd-a9e8-b0428ba4378c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5863af-27b0-429d-9645-5cd2c78dcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5d208-2022-406e-8577-37893f74cd54",
   "metadata": {},
   "source": [
    "**What algorithms I might like to include in assessment?**\n",
    "1. Decision Tree (explanation)/ gini impurity/ID3\n",
    "2. Random Forest (prediction)/bootstrap aggregating/bagging\n",
    "3. pruning algorithms/information gain/minimal cost-complexity pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40229fa1-9cd4-42ed-b04f-c2c23e8d8371",
   "metadata": {},
   "source": [
    "### Gini Impurity (decision tree) (supervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4d0f95-9daf-4823-af95-2e680ec8a1ab",
   "metadata": {},
   "source": [
    "\n",
    "Random forest may be a flexible, easy to use machine learning algorithm that produces, even without hyper-parameter tuning, an excellent result most of the time.\n",
    "\n",
    "Itâ€™s also one among the foremost used algorithms, due to its simplicity and variety (it are often used for both classification and regression tasks).\n",
    "\n",
    "Random Forests are an ensemble learning method that is for performing classification, regression as well as other tasks through the construction of decision trees and providing the output as a class which is the mode or mean of the underlying individual trees.\n",
    "\n",
    "A Decision Tree Classifier functions by breaking down a dataset into smaller and smaller subsets based on different criteria. Different sorting criteria will be used to divide the dataset, with the number of examples getting smaller with every division.\n",
    "\n",
    "Once the network has divided the data down to one example, the example will be put into a class that corresponds to a key. When multiple random forest classifiers are linked together they are called Random Forest Classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05be674-f014-4810-a13e-03d804a8e34c",
   "metadata": {},
   "source": [
    "**Classification Tree**\n",
    "- make tree for each variable, check and compare impurity among variables (Gini impurity, imformation gain, entropy)\n",
    "- Total Gini impurity = weighted average of gini impurities for the leaves\n",
    "- a bit more calculation if variable is numeric\n",
    "- variable with lowest impurity at the top of the tree, then calcualtion of Gini Imppurity starts again for the remaining variables as nodes, until no more split --> as leaf and categorize/classify them\n",
    "**confidence in classification and overfit**\n",
    "- Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aa41bd-9e0b-41ca-b80d-73cb7a4a2a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84badc65-3f64-4625-a167-af798fd070d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4965a80e-7e7f-4d77-a4cf-c84b50236f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cddb54df-5532-475d-886d-ca0677c850bc",
   "metadata": {},
   "source": [
    "### Bootstrap aggregating/baggin algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b32f2-6a5f-450a-af62-e059aa581379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a7f7d-ea6c-44d9-bb5b-cfe2e2f8a66a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e3bc0-d330-4488-b952-75c698800709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1f5e52-0399-41ec-aa86-2a039fe7f983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c01237df-0361-4f55-ad47-dab6589ae007",
   "metadata": {},
   "source": [
    "### Pruning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f14349-6c9d-43f6-b25a-dc4f232a5d52",
   "metadata": {},
   "source": [
    "#### random forest\n",
    "- because DT is easy to create but inaccurate to classify\n",
    "- bootstrapped dataset; consider a random subset of variables at each step; then repeat --> a wide variety of trees (the forest)\n",
    "- prediction, run data on all the trees in the forest, see which option received more votes\n",
    "- bagging: bootstrapping data + using the aggregate to make a decision\n",
    "- out of bag dataset(testing dataset): test which trees incorrectly predict --> out of bag error (the accuracy of the forest)\n",
    "<br>\n",
    "Flow:\n",
    "1. build a random forest\n",
    "2. estimate accuracy of the forest --> change number of variables used per step\n",
    "3. then repeat a bunch of times\n",
    "**Clustering**\n",
    "- fill in missing value by guess then refine guesses by running down the trees till the guess converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389f7e2-9848-4ef7-ad4c-13ebd64b9a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96624caa-b606-4f46-b219-05fb162ae79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bfbe2f2-31f6-4864-ba4f-80ed4f7b2d01",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e5c43c-3c4c-41f4-9505-91cede6efa19",
   "metadata": {},
   "source": [
    "***\n",
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
